{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Sesión 1: Estudio de Transfer Learning con TensorFlow\n",
    "\n",
    "Tutorial de Transfer Learning y Fine Tuning.  \n",
    "\n",
    "TMO: Técnicas metaheurísticas y de optimización.\n",
    "[Máster en Data Science y Big Data](http://masterds.es/) de la [Universidad de Sevilla](http://www.us.es). \n",
    "\n",
    "Profesor: [Miguel Ángel Martínez del Amor](http://www.cs.us.es/~mdelamor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla de Contenidos\n",
    "\n",
    "* [1. Introducción](#intro)\n",
    "* [2. Jugando con Inception V3](#inception)\n",
    "  * [2.1 Arquitectura de la red](#inceparq)\n",
    "  * [2.2 Importación de librerías y descarga del modelo](#incepimp)\n",
    "  * [2.3 Clasificación de imágenes](#incepclasif)\n",
    "  * [2.4 Experimentación y cierre de sesión](#incepcierre)\n",
    "  * [2.5 Conclusiones](#incepconclu)\n",
    "* [3. Estudio de Transferibilidad](#datatransfer)\n",
    "  * [3.1 El Dataset: Knifey-Spoony](#transferdata)\n",
    "  * [3.2 Funciones Auxiliares](#transferaux)\n",
    "  * [3.3 Dibujar Algunas Imágenes de Prueba](#transferprueba)\n",
    "  * [3.4 Descarga del Modelo Inception](#transfermodelo)\n",
    "  * [3.5 Cálculo de Valores de Transferencia](#transfercalc)\n",
    "  * [3.6 Función Auxiliar para Mostrar Valores de Transferencia](#transfergraphval)\n",
    "  * [3.7 Análisis de Valores de Transferencia mediante PCA](#transferpca)\n",
    "  * [3.8 Análisis de Valores de Transferencia mediante t-SNE](#transfertsne)\n",
    "  * [3.9 Conclusiones](#transferconc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si estás en Google Colab, habilita las siguientes líneas y evalúa la celda:\n",
    "#import os\n",
    "#work_dir = \"/content/TL-tutorial/\"\n",
    "#if os.getcwd() != work_dir:\n",
    "#    !git clone https://github.com/miguelamda/TL-tutorial.git\n",
    "#os.chdir(work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción <a class=\"anchor\" id=\"intro\"></a>\n",
    "\n",
    "En este tutorial profundizaremos más en el concepto de transfer learning (transferencia de aprendizaje), siendo aplicado a visión por computador. Comenzaremos utilizando un modelo pre-entrenado en algunas imágenes, comprendiendo qué es lo que podemos obtener de ellos. A continuación, intentaremos entrenar una red sobre un conjunto de imágenes para posteriormente mejorarlo con modelos pre-entrenados mediante transfer learning y fine tuning, visualizando qué comportamiento obtendremos.\n",
    "\n",
    "En este tutorial utilizaremos [Keras](https://keras.io/), una API de alta abstracción que se puede usar sobre [TensorFlow](https://www.tensorflow.org). Usaremos primero el modelo Inception V3, y posteriormente para trabajar el VGG16, dado que su arquitectura es más sencilla. Se aconseja emplear una [GPU con arquitectura para Deep Learning](https://timdettmers.com/2019/04/03/which-gpu-for-deep-learning/) (recomendado una GPU de NVIDIA con arquitectura Kepler, Pascal, Volta o Turing), por lo que si no se tiene una en local se recomienda acceder a un servidor o a una plataforma en la nube como [Google Colab](https://colab.research.google.com/).\n",
    "\n",
    "Antes de continuar, se debe tener un mínimo de conocimiento sobre Machine Learning, y también algunas nociones básicas de Deep Learning, como por ejemplo comprender que son las características y cómo las aprende una red neuronal profunda. Para entender ésto último de forma visual, se recomienda este vídeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Youtube\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/AgkfIQ4IGaM\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Jugando con Inception V3 <a class=\"anchor\" id=\"inception\"></a>\n",
    "\n",
    "Este tutorial muestra cómo usar una Red Neural Profunda pre-entrenada llamada Inception v3 para la clasificación de imágenes.\n",
    "\n",
    "El modelo Inception v3 tardó semanas en entrenarse sobre ImageNet (millones de imágenes) en un ordenador con 8 GPUs Tesla K40 que probablemente cuesta 30.000 euros, por lo que es imposible entrenarlo en un PC normal. En su lugar, descargaremos el modelo de Inception previamente entrenado y lo usaremos para clasificar las imágenes.\n",
    "\n",
    "El modelo Inception v3 tiene casi 25 millones de parámetros y utiliza 5.000 millones de operaciones de multiplicación para clasificar una sola imagen. En un PC moderno sin GPU, esto se puede hacer en una fracción de segundo por imagen.\n",
    "\n",
    "Este tutorial oculta el código TensorFlow, por lo que puede que no requiera mucha experiencia con TensorFlow, aunque una comprensión básica de TensorFlow puede ser útil, especialmente si desea estudiar los detalles de implementación en el archivo [`inception.py`](./inception.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Arquitectura de la red <a class=\"anchor\" id=\"inceparq\"></a>\n",
    "\n",
    "La siguiente figura muestra cómo fluyen los datos en el modelo Inception v3, que es una Red Neural Convolucional con muchas capas y una estructura complicada. El [artículo](http://arxiv.org/pdf/1512.00567v3.pdf) ofrece más detalles sobre cómo se construye el modelo Inception y por qué se diseña de esa manera. Pero los autores admiten que no entienden del todo por qué funciona. \n",
    "\n",
    "Ten en cuenta que el modelo Inception tiene dos salidas softmax. Uno se usa durante el entrenamiento de la red neural como regularizador y el otro se usa para clasificar imágenes después de que el entrenamiento haya terminado, es decir, para inferencia. Para entender mejor los detalles de la red, se puede leer este [artículo](https://medium.com/@sh.tsang/review-inception-v3-1st-runner-up-image-classification-in-ilsvrc-2015-17915421f77c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "Image('images/07_inception_flowchart.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Importación de librerías y descarga del modelo <a class=\"anchor\" id=\"incepimp\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Archivo auxiliar 'inception.py' con funciones y clases para cargar y usar el modelo inception\n",
    "import inception\n",
    "\n",
    "# Comprobar nuestra versión de tensorflow\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo Inception se descarga desde internet. Esta es la carpeta por defecto donde se descarán los ficheros correspondientes. El directorio se creará si no existe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception.data_dir = 'inception/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si aún no has descargado el modelo, lo puedes hacer con la siguiente instrucción. Tomará unos 85Mb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.maybe_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, carga el modelo para poder emplearlo a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inception.Inception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Clasificación de imágenes <a class=\"anchor\" id=\"incepclasif\"></a>\n",
    "\n",
    "Antes de continuar, vamos a definir una función auxiliar que nos ayudará en la tarea de clasificar imágenes: muestra la imagen, la clasifica usando el modelo cargado, e imprime las puntuaciones (scores) de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(image_path):\n",
    "    # Muestra la imagen.\n",
    "    display(Image(image_path))\n",
    "\n",
    "    # Usa el modelo Inception para clasificar la imagen.\n",
    "    pred = model.classify(image_path=image_path)\n",
    "\n",
    "    # Muestra los scores y los nombres del top-10 de las predicciones.\n",
    "    model.print_scores(pred=pred, k=10, only_first_name=True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Panda\n",
    "\n",
    "Esta imagen de un panda se incluye en el archivo de datos de Inception. El modelo Inception está bastante seguro de que esta imagen muestra un panda, con una puntuación de clasificación de alrededor del 89% y la siguiente puntuación más alta es de sólo alrededor del 0,8% para un indri, que es otro animal exótico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join(inception.data_dir, 'cropped_panda.jpg')\n",
    "classify(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretación de las puntuaciones de clasificación\n",
    "\n",
    "El resultado del modelo Inception es la llamada función **Softmax**. Las salidas softmax son a veces llamadas probabilidades porque están entre cero y uno, y también suman uno - igual que las probabilidades. Pero en realidad no son probabilidades en el sentido tradicional de la palabra, porque no provienen de experimentos repetidos.\n",
    "\n",
    "Tal vez sea mejor llamar a los valores de salida de una red neuronal las *puntuaciones o rangos de clasificación*, porque indican con qué certeza cree la red que la imagen de entrada es de cada clase posible.\n",
    "\n",
    "En el ejemplo anterior con la imagen de un panda, el modelo Inception dio una puntuación muy alta de alrededor del 89% para la clase panda, y las puntuaciones para las 999 clases posibles restantes estaban todas por debajo del 1%. Esto significa que el modelo de Inception estaba bastante seguro de que la imagen mostraba un panda y que las puntuaciones restantes por debajo del 1% debían considerarse como ruido. Por ejemplo, la octava puntuación más alta fue del 0,05% para un reloj digital, pero esto se debe probablemente más a la naturaleza imprecisa de las redes neuronales que a una indicación de que la imagen se parecía ligeramente a un reloj digital.\n",
    "\n",
    "A veces el modelo Inception se confunde con la clase a la que pertenece una imagen, por lo que ninguna de las puntuaciones es realmente alta. A continuación se muestran ejemplos de ello."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loro (Parrot)\n",
    "##### Imagen Original\n",
    "\n",
    "El modelo Inception está muy seguro (puntuación sobre 97%) de que esta imagen muestra un tipo de loro llamado guacamayo (macaw)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(image_path=\"images/parrot.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imagen Redimensionada\n",
    "\n",
    "El modelo Inception funciona con imágenes de entrada de 299 x 299 píxeles de tamaño. La imagen de arriba de un loro tiene en realidad 320 píxeles de ancho y 785 píxeles de alto, por lo que es redimensionada automáticamente por el modelo Inception.\n",
    "\n",
    "Ahora queremos ver la imagen después de que haya sido redimensionada por el modelo Inception. Primero tenemos una función de ayuda para obtener la imagen redimensionada desde dentro del modelo Inception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_resized_image(image_path):\n",
    "    # Toma la imagen redimensionada del modelo Inception\n",
    "    resized_image = model.get_resized_image(image_path=image_path)\n",
    "\n",
    "    # Muestra la imagen.\n",
    "    plt.imshow(resized_image, interpolation='nearest')\n",
    "    \n",
    "    # Se asegura de que la gráfica se muestre.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora traza la imagen del loro al nuevo tamaño. Esta es la imagen que se introduce en la red neuronal del modelo Inception. Podemos ver que ha sido apretado para que sea cuadrado, y la resolución se ha reducido para que la imagen sea más pixelada y granulada.\n",
    "\n",
    "En este caso, la imagen todavía muestra claramente un loro, pero algunas imágenes pueden distorsionarse tanto a partir de este ingenuo cambio de tamaño que puede que desees cambiar el tamaño de las imágenes tú mismo antes de introducirlas en el modelo Inception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_resized_image(image_path=\"images/parrot.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imagen Recortada, arriba\n",
    "\n",
    "Esta imagen del loro se ha recortado manualmente a 299 x 299 píxeles y luego se ha introducido en el modelo Inception,\n",
    "que sigue estando muy seguro (puntuación de alrededor del 97%) de que muestra un loro (guacamayo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(image_path=\"images/parrot_cropped1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imagen Recortada, en el centro\n",
    "\n",
    "Esto es otro recorte de la imagen del loro, esta vez mostrando su cuerpo sin cabeza ni cola. El modelo Inception sigue teniendo mucha confianza (puntuación de alrededor del 94%) de que muestra un loro guacamayo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(image_path=\"images/parrot_cropped2.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imagen Recortada, abajo\n",
    "\n",
    "Esta imagen ha sido recortada por lo que sólo muestra la cola del loro. Ahora el modelo Inception está bastante confundido y piensa que la imagen podría mostrar un jacamar (puntuación de alrededor del 26%) que es otro ave exótica, o quizás la imagen muestra un saltamontes (grass-hopper, puntuación de alrededor del 10%).\n",
    "\n",
    "El modelo Inception también piensa que la imagen podría mostrar una pluma estilográfica (fountain-pen, puntuación aproximada del 2%). Pero esta es una puntuación muy baja y debe interpretarse como un ruido poco fiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(image_path=\"images/parrot_cropped3.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imagen Rellenada\n",
    "\n",
    "La mejor manera de introducir imágenes en este modelo Inception, es rellenar la imagen para que sea cuadrada (en blanco a los lados) y luego redimensionarla a 299 x 299 píxeles, como este ejemplo del loro que está clasificado correctamente con una puntuación de alrededor del 97%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(image_path=\"images/parrot_padded.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elon Musk\n",
    "\n",
    "##### 299 x 299 píxeles\n",
    "\n",
    "Esta imagen muestra a la leyenda viviente Elon Musk. Pero el modelo de Inception está muy confundido sobre lo que muestra la imagen, prediciendo que puede mostrar una sudadera (sweatshirt, puntuación alrededor del 17%) o una abaya (puntuación alrededor del 16%). También piensa que la imagen podría mostrar una pelota de ping-pong (ping-pong ball, puntuación de alrededor del 3%) o una pelota de béisbol (baseball, puntuación de alrededor del 2%). Por lo tanto, el modelo Inception está confuso y las puntuaciones de la clasificación no son fiables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(image_path=\"images/elon_musk.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 100 x 100 píxeles\n",
    "\n",
    "Si en su lugar usamos una imagen de 100 x 100 píxeles de Elon Musk, entonces el modelo de Inception piensa que podría mostrar una sudadera (sweatshirt, puntuación alrededor del 22%) o una bota de vaquero (cowboy boot, puntuación alrededor del 14%). Así que ahora el modelo Inception tiene predicciones algo diferentes, pero sigue estando muy confuso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(image_path=\"images/elon_musk_100x100.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo Inception escala automáticamente el tamaño de esta imagen de 100 x 100 a 299 x 299 píxeles, que se muestra aquí. Observa lo pixelado y granuloso que realmente es, aunque un humano puede ver fácilmente que esta es la imagen de un hombre con los brazos cruzados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_resized_image(image_path=\"images/elon_musk_100x100.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Willy Wonka \n",
    "\n",
    "##### Gene Wilder\n",
    "\n",
    "Esta imagen muestra al actor Gene Wilder interpretando a Willy Wonka en la versión de la película de 1971. El modelo Inception está muy seguro de que la imagen muestra una pajarita (bow tie, puntuación de alrededor del 98%), lo que es cierto, pero un humano probablemente diría que esta imagen muestra a una persona.\n",
    "\n",
    "La razón podría ser que el modelo Inception fue entrenado en imágenes de personas con pajaritas que fueron clasificadas como pajaritas en lugar de personas. Así que tal vez el problema es que el nombre de la clase debería ser \"persona con pajarita\" en lugar de sólo \"pajarita\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(image_path=\"images/willy_wonka_old.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Johnny Depp\n",
    "\n",
    "Esta imagen muestra al actor Johnny Depp interpretando a Willy Wonka en la versión de 2005 de la película. El modelo Inception piensa que esta imagen muestra \"gafas de sol\" (sunglasses, puntuación aproximada del 34%) o \"gafa de sol\" (sunglass, puntuación aproximada del 18%). En realidad, el nombre completo de la primera clase es \"gafas de sol, gafas oscuras, sombras\". Por alguna razón, el modelo Inception ha sido entrenado para reconocer dos clases muy similares de gafas de sol. Una vez más, es cierto que la imagen muestra gafas de sol, pero un humano probablemente habría dicho que esta imagen muestra a una persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(image_path=\"images/willy_wonka_new.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Experimentación y Cierre de Sesión <a class=\"anchor\" id=\"incepcierre\"></a>\n",
    "\n",
    "Acabamos de concluir el apartado en el que hemos jugado con el modelo Inception v3, y visto algunas de sus limitaciones. A continuación puedes probar otras imágenes, tuyas o de internet, y ver si el modelo está confundido o no. Una vez terminado, cerraremos la sesión de TensorFlow, mediante el método correspondiente en el objeto *model*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba aquí imágenes tuyas o de internet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez terminado de experimentar y si no vas a continuar con el apartado 3, descomenta la siguiente línea y\n",
    "# ejecuta esta celda para cerrar la sesión de TensorFlow, para así liberar los recursos de GPU.\n",
    "\n",
    "#model.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Conclusión <a class=\"anchor\" id=\"incepconclu\"></a>\n",
    "\n",
    "Este apartado mostró cómo usar el modelo Inception v3 preentrenado. Un ordenador muy caro puede tarda varias semanas en entrenar el modelo Inception, pero podemos descargar el modelo terminado de Internet y usarlo en un PC normal para clasificar las imágenes.\n",
    "\n",
    "Desafortunadamente, el modelo Inception parece tener problemas para reconocer a las personas. Esto puede deberse al conjunto de entrenamiento que se utilizó. Ya se han publicado versiones más recientes del modelo Inception, pero es probable que también estén capacitados en el mismo conjunto de datos y, por lo tanto, también pueden tener problemas para reconocer a las personas. Se espera que los modelos futuros sean entrenados para reconocer objetos comunes como las personas.\n",
    "\n",
    "En este tutorial hemos ocultado la implementación de TensorFlow en el archivo `inception.py` porque es un poco desordenado y puede que queramos reutilizarlo. La nueva versión de TensorFlow ya incluye Keras, una API que simplifica la carga de estos modelos ya entrenados, de modo que cualquiera pueda usar un potente clasificador de imágenes con sólo unas pocas líneas de código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Estudio de Transferibilidad  <a class=\"anchor\" id=\"datatransfer\"></a>\n",
    "\n",
    "En este apartado vamos a introducir el dataset que emplearemos para hacer Transfer Learning, pero antes de pasar a la acción, nos detendremos para estudiar cómo de transferibles son las características aprendidas en InceptionV3 para este nuevo conjunto de datos.\n",
    "\n",
    "La siguiente figura muestra cómo fluyen los datos cuando se utiliza el modelo Inception para **Transferir el Aprendizaje** en **TensorFlow**. Primero introducimos y procesamos una imagen con el modelo Inception. Justo antes de la capa de clasificación final del modelo Inception, guardamos los llamados valores de transferencia (transfer-values) en un archivo caché.\n",
    "\n",
    "La razón por la que se utiliza un archivo caché es que se tarda mucho tiempo en procesar una imagen con el modelo Inception. Con un ordenador portátil con una CPU de 2 GHz de cuatro núcleos puede procesar aproximadamente 3 imágenes por segundo utilizando el modelo Inception. Si cada imagen se procesa más de una vez, podemos ahorrar mucho tiempo almacenando en caché los valores de transferencia.\n",
    "\n",
    "Los valores de transferencia también se denominan a veces valores de cuello de botella, pero es un término confuso, por lo que no se utiliza aquí.\n",
    "\n",
    "Cuando todas las imágenes del nuevo conjunto de datos han sido procesadas a través del modelo Inception y los valores de transferencia resultantes se guardan en un archivo cache, entonces podemos usar esos valores de transferencia como entrada a otra red neuronal. Luego se entrena la segunda red neuronal usando las clases del nuevo conjunto de datos, para que la red aprenda a clasificar las imágenes en base a los valores de transferencia del modelo Inception.\n",
    "\n",
    "En este apartado no vamos a entrenar una nueva red neuronal, sino que analizaremos las cachés de valores de transferencia para ver cómo de extrapolables son al nuevo conjunto de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Flowchart of Transfer Learning & Fine-Tuning](images/09_transfer_learning_flowchart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comencemos importando algunas librerías. Si ya las has cargado en el apartado anterior, entonces no las necesitas cargar de nuevo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "# Funciones y clases para cargar y usar el modelo InceptionV3 con Tensorflow.\n",
    "import inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 El Dataset: Knifey-Spoony <a class=\"anchor\" id=\"transferdata\"></a>\n",
    "\n",
    "Para demostrar como usar transfer learning y fine tuning en este tutorial, usaremos un nuevo conjunto de datos llamado [Knifey-Spoony](https://github.com/Hvass-Labs/knifey-spoony) que contiene miles de imágenes de cuchillos, cucharas y tenedores sobre unos cuantos fondos diferentes. El conjunto de entrenamiento (training) contiene 4.170 imágenes y el de pruebas (test) 530 imágenes. Las clases se denominan knifey, spoony y forky como referencia a [Los Simpsons](https://www.youtube.com/watch?v=mcE0aAhbVFc).\n",
    "\n",
    "Las imágenes en el conjunto de datos knifey-spoony fueron creadas a partir de archivos de vídeo usando un pequeño [script de Python](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/convert.py) que se ejecuta en Linux (requiere el programa `avconv` para la conversión de videos a imágenes). Esto le permite crear fácilmente conjuntos de datos muy grandes con miles de imágenes de sólo unos minutos de grabaciones de vídeo.\n",
    "\n",
    "La descarga y la extracción del dataset ya viene automatizado en el fichero [`knifey.py`](./knifey.py). Las dimensiones de los datos ya están definidos en el módulo `knifey`, por lo que tan solo necesitamos importar las que necesitamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga el dataset empleando el fichero kinfey.py\n",
    "import knifey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descarga y extrae el dataset si aún no se ha hecho. Ocupa unos 22 MB. A continuación, mostramos el contenido de la carpeta extraida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knifey.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora cargamos el conjunto de datos. Esto escanea los subdirectorios en busca de todas las imágenes `*.jpg` y pone los nombres de archivo en dos listas para el conjunto de entrenamiento y el conjunto de pruebas. Esto no carga realmente las imágenes, lo que se hará cuando los valores de transferencia se calculen más adelante.\n",
    "\n",
    "Las listas de nombres de archivos se almacenan en caché en el disco duro, de modo que podemos estar seguros de que se ordenan de la misma manera cuando se recarga el conjunto de datos más tarde. Esto es importante para saber qué archivo de imagen corresponde a qué valores de transferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = knifey.data_dir\n",
    "dataset = knifey.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtengamos los nombres y el número de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = dataset.num_classes\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora obtenemos el conjunto de entrenamiento. Esto devuelve las rutas de los ficheros para las imágenes, las clases como enteros, y las clases codificadas en arrays One-Hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_train, cls_train, labels_train = dataset.get_training_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos imprimir la primera ruta para ver si está bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora obtenemos el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_test, cls_test, labels_test = dataset.get_test_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos ahora la primera ruta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos Knifey-Spoony ha sido cargado y consiste en 4700 imágenes con etiquetas asociadas (es decir, clasificaciones de las imágenes). El conjunto de datos se divide en dos subconjuntos mutuamente excluyentes, el conjunto de entrenamiento y el conjunto de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(image_paths_train)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(image_paths_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Funciones Auxiliares <a class=\"anchor\" id=\"transferaux\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Para Dibujar Imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función es utilizada para dibujar un máximo de 9 imágenes en una cuadrícula de 3x3, y escribir las clases verdaderas y previstas debajo de cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None, smooth=True):\n",
    "\n",
    "    assert len(images) == len(cls_true)\n",
    "\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    # Adjust vertical spacing.\n",
    "    if cls_pred is None:\n",
    "        hspace = 0.3\n",
    "    else:\n",
    "        hspace = 0.6\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=0.3)\n",
    "\n",
    "    # Interpolation type.\n",
    "    if smooth:\n",
    "        interpolation = 'spline16'\n",
    "    else:\n",
    "        interpolation = 'nearest'\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # There may be less than 9 images, ensure it doesn't crash.\n",
    "        if i < len(images):\n",
    "            # Plot image.\n",
    "            ax.imshow(images[i],\n",
    "                      interpolation=interpolation)\n",
    "\n",
    "            # Name of the true class.\n",
    "            cls_true_name = class_names[cls_true[i]]\n",
    "\n",
    "            # Show true and predicted classes.\n",
    "            if cls_pred is None:\n",
    "                xlabel = \"True: {0}\".format(cls_true_name)\n",
    "            else:\n",
    "                # Name of the predicted class.\n",
    "                cls_pred_name = class_names[cls_pred[i]]\n",
    "\n",
    "                xlabel = \"True: {0}\\nPred: {1}\".format(cls_true_name, cls_pred_name)\n",
    "\n",
    "            # Show the classes as the label on the x-axis.\n",
    "            ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para Cargar Imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este conjunto de datos no carga las imágenes reales, sino que tiene una lista de las imágenes en el conjunto de entrenamiento y otra lista para las imágenes en el conjunto de pruebas. Esta función de ayuda carga algunos archivos de imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "\n",
    "def load_images(image_paths):\n",
    "    # Carga las imágenes de disco\n",
    "    images = [imread(path) for path in image_paths]\n",
    "\n",
    "    # La convierte a un numpy array.\n",
    "    return np.asarray(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Dibujar Algunas Imágenes de Prueba <a class=\"anchor\" id=\"transferprueba\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga las primeras imágenes del conjunto de prueba\n",
    "images = load_images(image_paths=image_paths_test[0:9])\n",
    "\n",
    "# Obtenemos las clases verdades de dichas imágenes\n",
    "cls_true = cls_test[0:9]\n",
    "\n",
    "# Muestra las imágenes con sus etiquetas\n",
    "plot_images(images=images, cls_true=cls_true, smooth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Descarga del Modelo Inception  <a class=\"anchor\" id=\"transfermodelo\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asumimos que el modelo Inception ya está descargado, lo cual hicimos en el apartado <a href=\"#incepimp\">2.2</a>. Si no cerraste la sesión con el modelo, descomenta las siguientes celdas y vuelve a ejecutarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inception.data_dir = 'inception/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model = inception.Inception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.5 Cálculo de Valores de Transferencia <a class=\"anchor\" id=\"transfercalc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos una función de auxiliar para cargar en caché los valores de transferencia del modelo Inception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inception import transfer_values_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asigna las rutas de ficheros para las cachés del conjunto de entrenamiento y de test (archivos .pkl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_cache_train = os.path.join(data_dir, 'inception-knifey-train.pkl')\n",
    "file_path_cache_test = os.path.join(data_dir, 'inception-knifey-test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing Inception transfer-values for training-images ...\")\n",
    "\n",
    "# Si los valores de transferencia ya han sido calculados entonces los recarga,\n",
    "# si no, los calcula y los guarda en ficheros caché.\n",
    "transfer_values_train = transfer_values_cache(cache_path=file_path_cache_train,\n",
    "                                              image_paths=image_paths_train,\n",
    "                                              model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing Inception transfer-values for test-images ...\")\n",
    "\n",
    "# Si los valores de transferencia ya han sido calculados entonces los recarga,\n",
    "# si no, los calcula y los guarda en ficheros caché.\n",
    "transfer_values_test = transfer_values_cache(cache_path=file_path_cache_test,\n",
    "                                             image_paths=image_paths_test,\n",
    "                                             model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba la forma (shape) del array con los valores de transferencia. Hay unas 4.170 imágenes en el conjunto de entrenamiento y por cada imagen hay unos 2048 valores de transferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igualmente, hay 530 imágenes para el conjunto de test con 2048 valores de transferencia para cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Función Auxiliar para Mostrar Valores de Transferencia <a class=\"anchor\" id=\"transfergraphval\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transfer_values(i):\n",
    "    print(\"Input image:\")\n",
    "    \n",
    "    # Dibuja la imagen i-ésima del conjunto de test.\n",
    "    image = imread(image_paths_test[i])\n",
    "    plt.imshow(image, interpolation='spline16')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Transfer-values for the image using Inception model:\")\n",
    "    \n",
    "    # Transforma los valores de transferencia en una imagen.\n",
    "    img = transfer_values_test[i]\n",
    "    img = img.reshape((32, 64))\n",
    "\n",
    "    # Dibuja la imagen para los valores de transferencia.\n",
    "    plt.imshow(img, interpolation='nearest', cmap='Reds')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_transfer_values(i=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_transfer_values(i=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Análisis de Valores de Transferencia mediante PCA <a class=\"anchor\" id=\"transferpca\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos el Análisis de Componentes Principales (PCA) de scikit-learn para reducir las dimensiones de la matriz (longitud del array) de los valores de transferencia de 2048 a 2 para que se puedan dibujar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un objeto PCA y asignamos la longitud de array objetivo a 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lleva un tiempo calcular el PCA. En este caso, el conjunto de datos no es tan grande, pero de lo contrario podría seleccionar una parte más pequeña del conjunto de entrenamiento para acelerar el cálculo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer_values = transfer_values_train[0:3000]\n",
    "transfer_values = transfer_values_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener los números de clase de las muestras que se seleccionó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls = cls_train[0:3000]\n",
    "cls = cls_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar que el array tiene 4.170 muestras y 2.048 valores de transferencia para cada muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transfer_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice PCA para reducir las matrices de valores de transferencia de 2048 a 2 elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values_reduced = pca.fit_transform(transfer_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar que ahora es un array con 4170 muestras y 2 valores por muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transfer_values_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de ayuda para dibujar el array reducido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(values, cls):\n",
    "    # Create a color-map with a different color for each class.\n",
    "    import matplotlib.cm as cm\n",
    "    cmap = cm.rainbow(np.linspace(0.0, 1.0, num_classes))\n",
    "\n",
    "    # Create an index with a random permutation to make a better plot.\n",
    "    idx = np.random.permutation(len(values))\n",
    "    \n",
    "    # Get the color for each sample.\n",
    "    colors = cmap[cls[idx]]\n",
    "\n",
    "    # Extract the x- and y-values.\n",
    "    x = values[idx, 0]\n",
    "    y = values[idx, 1]\n",
    "\n",
    "    # Plot it.\n",
    "    plt.scatter(x, y, color=colors, alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar los valores de transferencia que se han reducido utilizando PCA. Hay 3 colores diferentes para las diferentes clases en el conjunto de datos de la Knifey-Spoony. Los colores tienen una superposición muy grande. Esto puede deberse a que la PCA no puede separar adecuadamente los valores de transferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_scatter(transfer_values_reduced, cls=cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Análisis de Valores de Transferencia mediante t-SNE <a class=\"anchor\" id=\"transfertsne\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro método para hacer la reducción de la dimensionalidad es t-SNE. Desafortunadamente, t-SNE es muy lento, así que primero usamos PCA para reducir los valores de transferencia de 2048 a 50 elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "transfer_values_50d = pca.fit_transform(transfer_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un nuevo objeto t-SNE para la reducción de la dimensionalidad final y establecemos el objetivo en 2-dim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la reducción final utilizando t-SNE. La implementación actual de t-SNE en scikit-learn no puede manejar datos con muchas muestras, por lo que esto puede fallar si utilizamos el conjunto de entrenamiento completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values_reduced = tsne.fit_transform(transfer_values_50d) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que ahora es un array con 4170 muestras y 2 valores de transferencia por muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transfer_values_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos los valores de transferencia que han sido reducidos a 2-dim usando t-SNE, lo que muestra una mejor separación que el gráfico PCA de arriba.\n",
    "\n",
    "Esto significa que los valores de transferencia del modelo Inception parecen contener suficiente información para separar las imágenes de Knifey-Spoony en clases, aunque todavía hay cierta superposición, por lo que la separación no es perfecta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_scatter(transfer_values_reduced, cls=cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Conclusiones <a class=\"anchor\" id=\"transferconc\"></a>\n",
    "\n",
    "Hemos trabajado con un conjunto de datos que emplearemos en la sesión 2 para Transfer Learning. Hemos también estudiado si la distribución de los valores de transferencia son suficientemente separables para las 3 clases, para que de este modo el clasificador final sea capaz de discriminarlos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License (MIT)\n",
    "\n",
    "Based on the TensorFlow tutorials by [Magnus Erik Hvass Pedersen](http://www.hvass-labs.org/)\n",
    "/ [GitHub](https://github.com/Hvass-Labs/TensorFlow-Tutorials) / [Videos on YouTube](https://www.youtube.com/playlist?list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZ)\n",
    "\n",
    "Copyright (c) 2016-2017 by [Magnus Erik Hvass Pedersen](http://www.hvass-labs.org/)\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
