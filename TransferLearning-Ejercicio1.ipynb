{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearning-Ejercicio1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguelamda/TL-tutorial/blob/master/TransferLearning-Ejercicio1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni9VMY1GIYlK"
      },
      "source": [
        "# Ejercicio 1. Transfer Learning con VGG16\n",
        "\n",
        "Ejercicio 1 del tutorial de Transfer Learning.\n",
        "\n",
        "GPT2: Diseño y Gestión de Proyectos en Data Science II.\n",
        "[Máster en Data Science y Big Data](http://masterds.es/) de la [Universidad de Sevilla](http://www.us.es). \n",
        "\n",
        "28/05/2021. Profesor: [Miguel Ángel Martínez del Amor](http://www.cs.us.es/~mdelamor)\n",
        "\n",
        "Este ejercicio puede ayudar a mejorar las habilidades con Keras. Para ello se propone emplear el modelo VGG16, el cual es más sencillo y que ya habéis visto en clase (o accediendo [aquí](https://github.com/miguelamda/DL/blob/master/5.%20Redes%20Convolucionales/Practica5.3.%20CNN%20Preentrenadas.ipynb)). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jBmnvUlIYlO"
      },
      "source": [
        "## 1. Importación de librerías y funciones auxiliares <a class=\"anchor\" id=\"transferimp\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkW86UqQKaJf"
      },
      "source": [
        "# Antes de nada, si estás en Google Colab, evalúa esta celda:\n",
        "import os\n",
        "work_dir = \"/content/TL-tutorial/\"\n",
        "if os.getcwd() != work_dir:\n",
        "    !git clone https://github.com/miguelamda/TL-tutorial.git\n",
        "os.chdir(work_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvEmFXz-IYlP"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSF6L-hDh4Yn"
      },
      "source": [
        "# FIXME: Comprueba aquí qué GPU tienes. Si no, solicita una y vuelve a lanzarlo."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QO-LQbbIYlb"
      },
      "source": [
        "A continuación la importación de la API de Keras. Como **primer ejercicio**, busca como se llama la función que carga el modelo VGG16, e impórtala en la celda siguiente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFQhw0KuIYlc"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "\n",
        "# FIXME: Importa a continuación la función que carga el modelo VGG16\n",
        "from keras.applications import ???\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRUx2exEIYlg"
      },
      "source": [
        "Vamos a usar las mismas funciones auxiliares que en el tutorial, las tienes a continuación, todas en una sola celda para definirlas más rápido. Aquí no hay nada que cambiar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO5HEcP5IYd6"
      },
      "source": [
        "def path_join(dirname, filenames):\n",
        "    return [os.path.join(dirname, filename) for filename in filenames]\n",
        "\n",
        "def plot_images(images, cls_true, cls_pred=None, smooth=True):\n",
        "\n",
        "    assert len(images) == len(cls_true)\n",
        "\n",
        "    # Crea una figura con sub-gráficas.\n",
        "    fig, axes = plt.subplots(3, 3)\n",
        "\n",
        "    # Ajusta el espacio vertical.\n",
        "    if cls_pred is None:\n",
        "        hspace = 0.3\n",
        "    else:\n",
        "        hspace = 0.6\n",
        "    fig.subplots_adjust(hspace=hspace, wspace=0.3)\n",
        "\n",
        "    # Tipo de interpolación.\n",
        "    if smooth:\n",
        "        interpolation = 'spline16'\n",
        "    else:\n",
        "        interpolation = 'nearest'\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        # Puede haber menos de 9 imágenes, nos aseguramos que no falle.\n",
        "        if i < len(images):\n",
        "            # Dibuja imagen.\n",
        "            ax.imshow(images[i],\n",
        "                      interpolation=interpolation)\n",
        "\n",
        "            # Number de la true class.\n",
        "            cls_true_name = class_names[cls_true[i]]\n",
        "\n",
        "            # Muestra clases predichas y verdaderas.\n",
        "            if cls_pred is None:\n",
        "                xlabel = \"True: {0}\".format(cls_true_name)\n",
        "            else:\n",
        "                # Nombre de la clase predicha.\n",
        "                cls_pred_name = class_names[cls_pred[i]]\n",
        "\n",
        "                xlabel = \"True: {0}\\nPred: {1}\".format(cls_true_name, cls_pred_name)\n",
        "\n",
        "            # Muestra las clases con la etiqueta en el eje x.\n",
        "            ax.set_xlabel(xlabel)\n",
        "        \n",
        "        # Elimina ticks en la gráfica.\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "    \n",
        "    # Asegurar que la gráfica se muestra correctamente con gráficos múltiples\n",
        "    # en una sola celda Notebook.\n",
        "    plt.show()\n",
        "    \n",
        "# Importa una función de sklearn para calcular la matriz de confusión.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def print_confusion_matrix(cls_pred):\n",
        "    # cls_pred es un array del número de la clase predicha para\n",
        "    # todas las imágenes del conjunto de test.\n",
        "\n",
        "    # Obtiene la matriz de confusión usando sklearn.\n",
        "    cm = confusion_matrix(y_true=cls_test,  # True class para el conjunto de test.\n",
        "                          y_pred=cls_pred)  # Predicted class.\n",
        "\n",
        "    print(\"Matriz de confusión:\")\n",
        "    \n",
        "    # Imprime la matriz de confusión como texto.\n",
        "    print(cm)\n",
        "    \n",
        "    # Imprime los nombres de clases para facilitar la referencia.\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        print(\"({0}) {1}\".format(i, class_name))\n",
        "        \n",
        "def plot_example_errors(cls_pred):\n",
        "    # cls_pred es un array del número de la clase predicha para\n",
        "    # todas las imágenes en el conjunto de test.\n",
        "\n",
        "    # Array booleano indicando si la clase predicha es incorrecta.\n",
        "    incorrect = (cls_pred != cls_test)\n",
        "\n",
        "    # Obtiene las rutas de ficheros para las imágenes que son clasificadas incorrectamente.\n",
        "    image_paths = np.array(image_paths_test)[incorrect]\n",
        "\n",
        "    # Carga las primeras 9 imágenes.\n",
        "    images = load_images(image_paths=image_paths[0:9])\n",
        "    \n",
        "    # Obtiene las clases predichas para esas imágenes.\n",
        "    cls_pred = cls_pred[incorrect]\n",
        "\n",
        "    # Obtiene las clases de verdad para esas imágenes.\n",
        "    cls_true = cls_test[incorrect]\n",
        "    \n",
        "    # Muestra las 9 imágenes que hemos cargado y sus correspondientes clases.\n",
        "    # Tenemos solo 9 imágenes, por lo que no hace falta dividirlas otra vez.\n",
        "    plot_images(images=images,\n",
        "                cls_true=cls_true[0:9],\n",
        "                cls_pred=cls_pred[0:9])\n",
        "    \n",
        "def example_errors(model=None):\n",
        "    # El generador de datos de Keras para el conjunto de test se debe resetear\n",
        "    # antes del procesamiento. Esto es porque el generador va a iterar\n",
        "    # infintamente y mantendrá un índice interno en el dataset.\n",
        "    # Por tanto, se podrá comenzar por el medio del conjunto de test si no lo\n",
        "    # reseteamos primero. Esto imposibilita encajar las clases predichas con\n",
        "    # las imágenes de entrada. Si reseteamos el generador, entonces siempre\n",
        "    # compienza por el comienzo, así que sabemos exáctamente qué imágenes\n",
        "    # de entrada se están usando.\n",
        "    if model is None:\n",
        "        model = new_model\n",
        "        \n",
        "    generator_test.reset()\n",
        "    \n",
        "    # Predecir las clases para todas las imágenes del conjunto de test.\n",
        "    y_pred = model.predict_generator(generator_test,\n",
        "                                      steps=steps_test)\n",
        "\n",
        "    # Convertir las clases predichas de arrays a enteros.\n",
        "    cls_pred = np.argmax(y_pred,axis=1)\n",
        "\n",
        "    # Muestra los ejemplos de imágenes mal clasificados.\n",
        "    plot_example_errors(cls_pred)\n",
        "    \n",
        "    # Muestra la matriz de confusión.\n",
        "    print_confusion_matrix(cls_pred)\n",
        "    \n",
        "def load_images(image_paths):\n",
        "    # Carga las imágenes de disco.\n",
        "    images = [plt.imread(path) for path in image_paths]\n",
        "\n",
        "    # Convierte a un array de numpy y lo devuelve.\n",
        "    return np.asarray(images)\n",
        "\n",
        "def plot_training_history(history):\n",
        "    # Obtiene la precisión de clasificación y el valor de pérdida para el\n",
        "    # conjunto de entrenamiento.\n",
        "    acc = history.history['categorical_accuracy']\n",
        "    loss = history.history['loss']\n",
        "\n",
        "    # También para el conjunto de validación (solo usamos el del conjunto de test).\n",
        "    val_acc = history.history['val_categorical_accuracy']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    # Muestra el valor del accuracy y pérdida para el conjunto de entrenamiento.\n",
        "    plt.plot(acc, linestyle='-', color='b', label='Training Acc.')\n",
        "    plt.plot(loss, 'o', color='b', label='Training Loss')\n",
        "    \n",
        "    # Muestra el del conjunto de test.\n",
        "    plt.plot(val_acc, linestyle='--', color='r', label='Test Acc.')\n",
        "    plt.plot(val_loss, 'o', color='r', label='Test Loss')\n",
        "\n",
        "    # Muestra el título y la leyenda.\n",
        "    plt.title('Training and Test Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Se asegura de mostrar la gráfica correctamente.\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExBplxfMIYlm"
      },
      "source": [
        "## 2. El Modelo Pre-Entrenado: VGG16 \n",
        "\n",
        "Lo siguiente crea una instancia del modelo VGG16 pre-entrenado usando la API de [Keras](https://keras.io/). Esto descarga automáticamente los archivos necesarios si no los tiene ya. \n",
        "\n",
        "El modelo VGG16 contiene una parte convolucional y una parte completamente conectada (o densa) que se utiliza para la clasificación. Si `include_top=True` entonces se descarga todo el modelo VGG16 que tiene unos 528 MB. Si `include_top=False` entonces sólo se descarga la parte convolucional del modelo VGG16, que es de sólo 57 MB. Descaragaremos la versión que incluya el clasificador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_jS1EYVIYlo"
      },
      "source": [
        "![VGG model](https://github.com/miguelamda/TL-tutorial/blob/master/images/11_vgg_model.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0TMoN3RIYlp",
        "scrolled": true
      },
      "source": [
        "vggmodel = ???? # FIXME: Descarga el modelo VGG16 con el clasificador"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saAfmzgGIYlt"
      },
      "source": [
        "## 3. El Dataset: Knifey-Spoony \n",
        "\n",
        "Carga el dataset tal y como se vió en el tutorial. A continuación las líneas de código."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBEvDoALGPrR"
      },
      "source": [
        "# Carga el dataset empleando el fichero kinfey.py\n",
        "import knifey\n",
        "\n",
        "# Descarga el dataset, si no se ha descargado ya\n",
        "knifey.maybe_download_and_extract()\n",
        "\n",
        "# Adapta la estructura de carpetas para Keras\n",
        "knifey.copy_files()\n",
        "\n",
        "# Define las rutas a los directorios de train y test\n",
        "train_dir = knifey.train_dir\n",
        "test_dir = knifey.test_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTWfUl-ZIYlt"
      },
      "source": [
        "## 4. El Canal de Entrada\n",
        "\n",
        "Para definir el pipeline de entrada para el modelo, primero necesitamos saber la forma de los tensores esperados como entrada por el modelo VGG16 pre-entrenado. En este caso, ¿qué forma tienen las imágenes de entrada?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCCzzSLEIYlu"
      },
      "source": [
        "input_shape = ???? # FIXME: cuál es el tamaño de entrada"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZVb4TpsIYlw"
      },
      "source": [
        "Define a continuación un *generador de datos* que haga aumentado mediante transformaciones aleatorias. Para VGG16, es necesario tan solo reescalar los píxeles a 1.0/255, así que no hace falta usar la función de preprocesamiento de entrada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHxjWS03IYlx"
      },
      "source": [
        "datagen_train = ???? # FIXME: crea un generador para train\n",
        "datagen_test = ???? # FIXME: crea un generador para test, sin aumentado de datos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3JX5692IYl0"
      },
      "source": [
        "Debido a que el modelo VGG16 es muy grande, el tamaño del batch no puede ser demasiado grande."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL3O-p5LIYl1"
      },
      "source": [
        "batch_size = ???? # FIXME: ajusta un tamaño de batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7cmwiLlIYl5"
      },
      "source": [
        "Podemos guardar las imágenes transformadas aleatoriamente durante el entrenamiento, para comprobar si han sido demasiado distorsionadas, por lo que tendríamos que ajustar los parámetros del generador de datos anterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6PWMMyaIYl5"
      },
      "source": [
        "if True:\n",
        "    save_to_dir = None\n",
        "else:\n",
        "    save_to_dir='augmented_images/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN_KAovWIYl-"
      },
      "source": [
        "Ahora creamos el generador de datos real que leerá los archivos del disco, redimensionará las imágenes y devolverá un lote aleatorio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9503pHv7IYl-",
        "scrolled": true
      },
      "source": [
        "generator_train = ????\n",
        "\n",
        "generator_test = ????"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CxntulPIYmB"
      },
      "source": [
        "Debido a que nuestro conjunto de pruebas contiene 530 imágenes y el tamaño del batch está configurado en 20, el número de pasos es 26,5 para un procesamiento completo del conjunto de pruebas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxPlmen3IYmC"
      },
      "source": [
        "steps_test = generator_test.n / batch_size\n",
        "steps_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITl4WRVAIYmG"
      },
      "source": [
        "## 5. Clases del Conjunto de Datos "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKMsQXiUKaJp"
      },
      "source": [
        "Obtengamos las rutas de los ficheros para todas las imágenes en los conjuntos de entrenamiento y de pruebas. Nos vendrá bien para las funciones auxiliares para visualizar ejemplos del conjunto de entrenamiento y de test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCgfSvwzKaJq"
      },
      "source": [
        "image_paths_train = path_join(train_dir, generator_train.filenames)\n",
        "image_paths_test = path_join(test_dir, generator_test.filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDZYmV9WIYmP"
      },
      "source": [
        "Obtengamos las clasificaciones reales (el número correspondiente: 0, 1 o 2) de cada imagen en los conjuntos de training y test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NBjj7-8IYmP"
      },
      "source": [
        "cls_train = generator_train.classes\n",
        "cls_test = generator_test.classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUOuHCXEIYmV"
      },
      "source": [
        "Obtengamos los nombres correspondientes de las clases del dataset y el número de ellos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKG8i_F_IYmV"
      },
      "source": [
        "class_names = list(generator_train.class_indices.keys())\n",
        "num_classes = generator_train.num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKAI0ppRIYmb"
      },
      "source": [
        "Dado que el conjunto de datos Knifey-Spoony está bastante desequilibrado porque tiene pocas imágenes de tenedores, más imágenes de cuchillos y muchas más imágenes de cucharas. Así que vamos a calcular **pesos** que equilibrarán adecuadamente el conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEtH-2iYIYmb"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weight = compute_class_weight(class_weight='balanced',\n",
        "                                    classes=np.unique(cls_train),\n",
        "                                    y=cls_train)\n",
        "\n",
        "class_weight = ??? # FIXME: adapta la salida para keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeU-Oh9RIYmd"
      },
      "source": [
        "## 6. Transfer Learning\n",
        "\n",
        "Primero imprimimos un resumen del modelo VGG16 para poder ver los nombres y tipos de sus capas, así como las formas de los tensores que fluyen entre las capas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UnlAnpaIYme"
      },
      "source": [
        "vggmodel.????  # FIXME: imprime el modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FTqKHLEIYmm"
      },
      "source": [
        "En este ejercicio vamos a extraer la parte convolucional de forma personalizada, es decir, desde la entrada hasta una capa deseada (de esta forma podrás hacer transfer learning desde otras capas). Comprueba como difiere esto a como lo habéis hecho en clase anteriormente (o [aquí](https://github.com/fsancho/DL/blob/master/4.%20Redes%20Convolucionales/4.3.%20CNN%20Preentrenadas.ipynb)).\n",
        "\n",
        "Podemos ver que la última capa convolucional se llama 'block5_pool', y podemos usar Keras para obtener una referencia a dicha capa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6jBeo8EIYmn"
      },
      "source": [
        "transfer_layer = vggmodel.get_layer('block5_pool')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5s6usqHIYmu"
      },
      "source": [
        "Nos referiremos a esta capa como la Capa de Transferencia (**Transfer Layer**), puesto que su salida será re-enrutada a nuestra nueva red neuronal completamente conectada que hará la clasificación final sobre el Knifey-Spoony dataset.\n",
        "\n",
        "La salida de la capa de transferencia tiene la siguiente forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5Lip8PPIYmv"
      },
      "source": [
        "transfer_layer.output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cWI7ePHIYmy"
      },
      "source": [
        "Es muy sencillo crear un nuevo modelo usando la API de Keras. Primero tomamos la parte del modelo VGG16 desde su capa de entrada hasta la salida de la capa de transferencia. Podemos llamarlo el modelo convolucional, porque consiste en todas las capas convolucionales del modelo VGG16."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_7qDWHrIYmy"
      },
      "source": [
        "conv_model = Model(inputs=vggmodel.input,\n",
        "                   outputs=transfer_layer.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPuxlkH5IYm2"
      },
      "source": [
        "Podemos entonces usar Keras para construir un modelo nuevo encima de este. Esta vez no vamos a usar la API funcional de Keras, sino que vamos a ir apilando."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBsCg7JpIYm3",
        "scrolled": true
      },
      "source": [
        "# FIXME: Creamos un nuevo modelo Secuencial de Keras\n",
        "nuevo_modelo = ????\n",
        "\n",
        "# FIXME: Añadimos la parte convolucional del modelo VGG16 de arriba\n",
        "nuevo_modelo.add(????)\n",
        "\n",
        "# FIXME: Aplanamos la salida del modelo VGG16 dado que ésta viene\n",
        "# de una capa convolucional. No uses una GAP, sino una flattern.\n",
        "nuevo_modelo.add(????)\n",
        "\n",
        "# FIXME: Añade una capa densa (es decir, totalmente conectada o fully-connected).\n",
        "# Esto es para combinar las características que el modelo VGG16 ha\n",
        "# reconocido en la imagen. Usa como función de activación ReLu.\n",
        "nuevo_modelo.add(????)\n",
        "\n",
        "# FIXME: Añade una capa dropout el cual prevendrá el sobreajuste y mejorará\n",
        "# la capacidad de generalización en datos desconocidos (es decir, el \n",
        "# conjunto de test). Usa un ratio de 0.5\n",
        "nuevo_modelo.add(????)\n",
        "\n",
        "# FIXME: Añade la capa final para la clasificación real, usando softmax.\n",
        "nuevo_modelo.add(????)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt3OZNzqIYm5"
      },
      "source": [
        "Utilizamos el optimizador Adam con una tasa de aprendizaje bastante baja de 1e-5. La tasa de aprendizaje podría ser mayor, pero si se intenta entrenar más capas del modelo original VGG16, entonces la velocidad de aprendizaje debería ser bastante baja, de lo contrario los pesos preentrenados del modelo VGG16 se distorsionarán y no podrá aprender."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJRnpx1jIYm6"
      },
      "source": [
        "optimizer = ????  # FIXME: usa Adam con learning rate 1e-5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-57CuXcEIYm8"
      },
      "source": [
        "Tenemos 3 clases en el Knifey-Spoony dataset, por lo que Keras necesita usar una **función de pérdida** (loss function)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VakMjiDlIYm8"
      },
      "source": [
        "loss = ???? # FIXME: cuál necesitamos?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8BJ_RATIYm_"
      },
      "source": [
        "La única **métrica de rendimiento** en la que estamos interesados es en la precisión de clasificación (clasiffication accuracy)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWL9wENYIYm_"
      },
      "source": [
        "metrics = ???? # FIXME: usa un accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KaJjO4CIYnC"
      },
      "source": [
        "Función auxiliar para imprimir si la capa en el modelo VGG16 debe ser entrenada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH-TU1-2IYnD"
      },
      "source": [
        "def print_layer_trainable():\n",
        "    for layer in conv_model.layers:\n",
        "        print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))\n",
        "        \n",
        "print_layer_trainable()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9P6HBDBIYnH"
      },
      "source": [
        "Por defecto, todas las capas del modelo VGG16 son entrenables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCOodbuvIYnI"
      },
      "source": [
        "En transfer learning estamos inicialmente interesados tan solo en reusar el modelo VGG16 tal cual, como un **extractor de características**, por lo que deshabilitaremos el entrenamiento en todas sus capas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwlonlTlIYnJ"
      },
      "source": [
        "conv_model.???? = False  # FIXME: bloquea el modelo convolucional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjBmyocjIYnN"
      },
      "source": [
        "for layer in ????:  # FIXME: bloquea las capas\n",
        "    layer.???? = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46B8BRI9IYnQ"
      },
      "source": [
        "print_layer_trainable()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g4uPwR8IYnS"
      },
      "source": [
        "Una vez que hayamos cambiado si las capas del modelos son entrenables, necesitamos compilarlo para que los cambios surtan efecto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fdf_8STIYnT"
      },
      "source": [
        "nuevo_modelo.????  # FIXME: compila el modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iask_euDIYnd"
      },
      "source": [
        "A continuación entrenamos el nuevo modelo, lo que se hace con tan solo una llamada a una función en la API de Keras. Definimos 15 épocas y necesitamos saber el número de pasos por época (según el tamaño de batch)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9Tby_mUIYne",
        "scrolled": true
      },
      "source": [
        "epochs = 20\n",
        "steps_per_epoch = # FIXME: cuántos pasos por época?\n",
        "history = nuevo_modelo.????  # FIXME: realiza el entrenamiento"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqKzBQnmIYno"
      },
      "source": [
        "Mostremos la gráfica de evolución de las métricas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPM9vkanIYnq",
        "scrolled": true
      },
      "source": [
        "plot_training_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqe72_2bIYnw"
      },
      "source": [
        "Después del entrenamiento también podemos evaluar el rendimiento del nuevo modelo en el conjunto de pruebas usando una sola llamada de función en la API de Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9Kb2mkyIYnw",
        "scrolled": true
      },
      "source": [
        "result = nuevo_modelo.????  # FIXME: evalúa el modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU1ltSOOIYn0",
        "scrolled": true
      },
      "source": [
        "print(\"Test-set classification accuracy: {0:.2%}\".format(result[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU1zeX9VIYn2"
      },
      "source": [
        "Podemos representar algunos ejemplos de imágenes mal clasificadas del conjunto de pruebas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzv7ra1xIYn2"
      },
      "source": [
        "example_errors(model=nuevo_modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mc4q8J-ZIYn4"
      },
      "source": [
        "### 7. Fine-Tuning\n",
        "\n",
        "Podemos tratar de afinar suavemente algunas de las capas más profundas del modelo VGG16 también. A esto lo llamamos \"Ajuste fino\", o **Fine Tuning**.\n",
        "\n",
        "No está claro si Keras usa el booleano `trainable` en cada capa del modelo original VGG16 o si es anulado por el booleano `trainable` en la 'meta-capa' que llamamos `conv_layer`. Así que habilitaremos el booleano `trainable` tanto para `conv_layer` como para todas las capas relevantes en el modelo original VGG16."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T2HZwcfIYn5"
      },
      "source": [
        "conv_model.???? = True  # FIXME: desbloquea"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AIFavVsIYn7"
      },
      "source": [
        "Queremos entrenar las últimas dos capas convolucionales, es decir, cuyos nombres contienen 'block5' o 'block4'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmNYiVoqIYn7"
      },
      "source": [
        "for layer in conv_model.????:\n",
        "    # FIXME: Booleano de si la capa es entrenable, vamos a desbloquear block5 y block 4\n",
        "    trainable = (???? in layer.name or ????? in layer.name)\n",
        "    \n",
        "    # FIXME: Ajusta el booleano de la capa\n",
        "    layer.???? = trainable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhxqtJ7pIYn8"
      },
      "source": [
        "Podemos comprobar que esto ha actualizado el booleano `trainable` para las capas relevantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMVFTd4nIYn8"
      },
      "source": [
        "print_layer_trainable()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j93hktLdIYn-"
      },
      "source": [
        "Usaremos el optimizador Adam con un bajo factor de aprendizaje bajo para el ajuste fino, 1e-7."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_r2O5iHIYn-"
      },
      "source": [
        "optimizer_fine = ????  # FIXME: baja el learning rate a adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibmrb2bSIYoD"
      },
      "source": [
        "Dado que hemos definido un nuevo optimizador y hemos cambiado los booleanos `trainable` para muchas de las capas en el modelo, necesitamos recompilarlo para que los cambios hagan efecto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9wcT5iGIYoE"
      },
      "source": [
        "nuevo_modelo.????  # FIXME: recompila el modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaVRbGXZIYoH"
      },
      "source": [
        "Continuamos por tanto con el entrenamiento por donde lo dejamos anteriormente, ahora aplicando fine-tuning al modelo VGG16 y el nuevo clasificador. Sigamos con 10 épocas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk0huhXRIYoH",
        "scrolled": true
      },
      "source": [
        "history = nuevo_modelo.???? # FIXME: re-entrena"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkBfoISEIYoJ"
      },
      "source": [
        "Luego podemos mostrar gráficamente los valores de pérdida y precisión de la clasificación a partir del entrenamiento. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRR60KjoIYoJ"
      },
      "source": [
        "plot_training_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj7i1NkNIYoM"
      },
      "source": [
        "result = nuevo_modelo.????  # FIXME: evalúa el modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI9aWsCsIYoO"
      },
      "source": [
        "print(\"Test-set classification accuracy: {0:.2%}\".format(result[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCt4vpP6IYoP"
      },
      "source": [
        "Podemos volver a mostrar algunos ejemplos de imágenes mal clasificadas, y también podemos ver en la matriz de confusión que el modelo sigue teniendo problemas para clasificar correctamente los tenedores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOohX753IYoQ",
        "scrolled": true
      },
      "source": [
        "example_errors(model=nuevo_modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaxJngmFLMDa"
      },
      "source": [
        "### 8. Ejercicios extra\n",
        "\n",
        "1. Repite el proceso sin los pesos de clases y comprueba cómo afecta al rendimiento.\n",
        "2. Repite el proceso sin aumentado de datos y comprueba cómo afecta al rendimineto.\n",
        "3. Usa otro modelo pre-entrenado de los disponibles en Keras y compara el rendimiento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O-QAjuHGPs-"
      },
      "source": [
        "## License (MIT)\n",
        "\n",
        "Based on the TensorFlow tutorials by [Magnus Erik Hvass Pedersen](http://www.hvass-labs.org/)\n",
        "/ [GitHub](https://github.com/Hvass-Labs/TensorFlow-Tutorials) / [Videos on YouTube](https://www.youtube.com/playlist?list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZ)\n",
        "\n",
        "Copyright (c) 2016-2017 by [Magnus Erik Hvass Pedersen](http://www.hvass-labs.org/)\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
      ]
    }
  ]
}